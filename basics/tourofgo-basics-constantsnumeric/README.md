# basics - constants (numeric values)

This uses a factored const. Shows bit shifting and type inference, but the type conversion is inconsistent. Just looking at the code, I would assume Big is a float. And because Small uses Big in its assignment, I would also assume Small is a float. In the **basics - types (conversion)** lesson, the conversion between types had to be explicit. In this lesson, Small is converted to an int and I don't get compile or runtime errors.
